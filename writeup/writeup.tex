\documentclass{article}

\usepackage{url,listings}
\lstset{
  language=Lisp,
  basicstyle=\ttfamily,
  showstringspaces=false}

\title{\texttt{ambc}: the most general \texttt{amb}}
\author{Jacob Hurwitz \and David Lawrence \and Steven Valdez}

\begin{document}

\maketitle

\begin{center}
  Source code is available at \url{http://github.com/dvorak42/pramb}.
\end{center}

\section{Introduction and motivation}

The \texttt{amb} function provides a clean mechanism for programs to make
discrete choices by implicit backtracking.  We aimed to extend \texttt{amb} so
that it might also represent decisions over an undetermined or possibly
infinite space of alternatives.  We were motivated by a desire to use
\texttt{amb} to manipulate random variables that might have particular
probability distributions.

We elected to implement a new interface called ``\texttt{amb}-continuation,''
or \texttt{ambc}.  Whereas \texttt{amb}'s argument is a list of alternatives,
\texttt{ambc}'s argument is a function that produces a new alternative
on-demand each time it's called. This function is passed success and failure
continuations so that it can indicate success (with a particular value) or
failure as appropriate.

\begin{lstlisting}
;;; Evaluates to 22 forever
(ambc
  (lambda (succeed fail)
    (succeed 22)))

;;; Fails immediately
(ambc
  (lambda (succeed fail)
    (fail)))
\end{lstlisting}

For \texttt{ambc} to be useful, it needs a way to maintain state between
invocations.  Accordingly, we guarantee that the parent environment of
\texttt{ambc}'s argument is not reset between successive calls.  With that
done, we can easily define traditional \texttt{amb} in terms of \texttt{ambc}:
\begin{lstlisting}
(define (amb . alts)
  (ambc
   (lambda (succeed fail)
     (if (null? alts)
         (fail)
         (let ((result (car alts)))
           (set! alts (cdr alts))
           (succeed result))))))
\end{lstlisting}

We can also implement non-determinism not possible with the normal
\texttt{amb}, such as pseudorandomly selecting from a range of
floating-point numbers:
\begin{lstlisting}
(define (amb-range low high)
  (ambc
   (lambda (succeed fail)
     (succeed (rand-float low high))))
\end{lstlisting}

In the remaining sections, we will discuss the implementation of
\texttt{ambc} and our efforts to use it as a mechanism for
representing random variables in Scheme.

\section{Implementation of \texttt{ambc}}

We started with the analyzing Scheme interpreter from problem set 4.
The failure continuations in this interpreter implicitly define a
stack, resulting in the backtracking procedure executing via
depth-first search.  However, depth-first search is not suitable when
there are nested choices from infinite sets of alternatives. Consider
the following code (from the problem set):
\begin{lstlisting}
(define (a-pythagorean-triple-from low)
  (let ((i (an-integer-starting-from low)))
    (let ((j (an-integer-starting-from i)))
      (let ((k (an-integer-starting-from j)))
        (require (= (+ (* i i) (* j j)) (* k k)))
        (list i j k)))))
\end{lstlisting}
A depth-first search would spend forever on the infinitely many
options for $k$ and would never try a new alternative for $i$ or $j$.

In order to explore the search space, we needed to use a breadth-first
search.  However, this came at the expense of simplicity: while a
depth-first search examines each state immediately after its parent
state, a breadth-first search hops back and forth between different
branches of the computation.  Therefore a breadth-first search must
explicitly allow the storage and restoration of all environment state.

\subsection{The environment store (\texttt{env.scm})}

The environment store is responsible for holding all environment
state.  This state is divided into two parts: the environment stack,
which keeps track of parent environments when multiple namespaces are
nested (e.g. within a \texttt{let}), and the procedure-environments
map, which stores the execution environment associated with each
procedure.

The environment stack is necessary for properly reverting state at the
end of a function call. (Formerly, this structure was implicitly
defined by analyzing procedures passing environments around.)  It
exposes APIs to push an environment, pop an environment, peek at the
top environment, save the a pointer to the current head, and restore
a saved head pointer.  The stack is simply implemented as a list.

The procedure-environments map is necessary so that procedures know in
which environment they should be executed.  This informaton was
formerly stored as an element of the compound-procedure object, but
such a technique no longer works because we need to swap out all
procedure environments each time backtracking occurs.  The
procedure-environments map is implemented as an alist which maps
procedure objects to environments.  This leads to the known issue that
procedure objects cannot be garbage-collected. We could have fixed the
problem by building the alist out of \texttt{weak-cons} cells, but
never got around to it because keeping old procedures in memory wasn't
a bottleneck.

Finally, we implemented functions to save all environment state
(i.e. both the environment stack and procedure-environments map) and
to restore all environment state from a saved copy.  The existence of
these procedures is what enabled us to perform backtracking via
breadth-first search.  These functions are quite inefficient in the
current implementation---they make a copy of all environments, even
though the majority will not be modified in each branch.

\subsection{The failure queue and backtracking (\texttt{ambc.scm})}

The new failure queue was much cleaner to implement than the previous
system of passing around failure continuations, as the majority of
analyzing functions no longer need to deal with failures at all.  The
queue exposes two global functions: \texttt{(add-branch continuation)}
to add a new branch to the end of the queue, and \texttt{(fail)} to
terminate the current branch and execute the next continuation from
the queue.  There is also a function called \texttt{*global-fail*},
which is called when the queue is empty. The repl hooks into this
function to print the ``no more alternatives'' message.

Given this framework, implementing backtracking was quite easy.  The
only remaining difficulty for implementing \texttt{ambc} was ensuring
that its argument returns cleanly.  Since the argument finishes by
escaping to an interpreter continuation rather than returning a value,
the \texttt{ambc} analyzer needs to clean up any environments that
were left on the stack.

\begin{lstlisting}
(define (analyze-ambc exp)
  (let ((fproc (analyze (cadr exp))))
    (lambda (succeed)
      (fproc (lambda (proc)
               (let loop ()
                 (define stack (grab-env-stack))
                 (execute-application
                  proc
                  (list (lambda (result)
                          (set-env-stack! stack)
                          (add-branch loop)
                          (succeed result))
                        fail)
                  (lambda (val)
                    (error "ambc argument returned")))))))))
\end{lstlisting}

\section{Applications to probability}

\subsection{Experiments with randomness}

One great use for \texttt{ambc} is sampling random points from a domain. For
example, using the definition of \texttt{amb-range} given above, you could
sample points from the unit circle as follows:
\begin{lstlisting}
(define (amb-unit-circle)
  (let ((x (amb-range -1 1))
        (y (amb-range -1 1)))
    (require (<= (+ (square x) (square y)) 1))
    (list x y)))
\end{lstlisting}

Unfortunately, this code is flawed and reveals a disadvantage of
breadth-first search. Consider the following transcript:
\begin{lstlisting}
;;; Amb-Eval input:
(amb-unit-circle)

;;; Starting a new problem
;;; Amb-Eval value:
(.8317830721369042 -.01663187759243523)

;;; Amb-Eval input:
try-again

;;; Amb-Eval value:
(-.3333454788948702 -.28896585308416034)

;;; Amb-Eval input:
try-again

;;; Amb-Eval value:
(.8317830721369042 -.3967400877386147)
\end{lstlisting}

The $x$-coordinates returned on the first and third calls are exactly
the same!  (As a reminder, the interpreter calls the failure
continuation upon receiving \texttt{try-again} as input, meaning that
it continues with the same breadth-first search.) The reason is
breadth-first search scheduling. The first call to
\texttt{amb-unit-circle} places its two children states on the queue:
one in which the next $x$ possibility is examined (which implicitly
also generates a new $y$), and one in which only the next $y$
possibility is examined. This is exactly what we want if both $x$ and
$y$ have an explicit list of alternatives and we want to examine the
space of all pairs of alternatives; however, when $x$ and $y$ are
randomly generated, it seems like sometimes keeping the same $x$ value
would yield a non-random distribution.

To confirm our suspicions, we ran a chi-squared test. We divided the
region $[-1,1]\times[-1,1]$ into 400 squares of equal area (each of
size $0.1\times 0.1$) and calculated the percent of the unit circle's
area that lies in each of these 400 squares. We then generated 3000
points using \texttt{amb-unit-circle}, counted how many points fell
into each of the 400 squares, and ran a chi-squared test of this
observed distribution of points against the expected (uniform random)
distribution. The test yielded a $p$-value of less than 0.0001,
indicating strong evidence that \texttt{amb-unit-circle} was not
sampling points uniformly at random from the desired distribution.

We came up with two possible workarounds for now. One is a function
\texttt{amb-ranges} that takes a parameter $n$ and returns an $n$-tuple:
\begin{lstlisting}
(define (amb-ranges n low high)
  (define (make-floats k)
    (if (= k 0)
        '()
        (cons (rand-float low high)
              (make-floats (- k 1)))))
  (ambc
    (lambda (succeed fail)
      (succeed (make-floats n)))))

(define (amb-unit-circle-ranges)
  (let ((point (amb-ranges 2 -1 1)))
    (require (<= (+ (square (car point))
                    (square (cadr point))) 1))
    point))
\end{lstlisting}

Another possible solution is to require the \texttt{ambc} for $y$ to fail on
every other call. This ensures that it succeeds if called immediately after a
new $x$ is generated, and otherwise fails (thus triggering the generation of a
new $x$).
\begin{lstlisting}
(define (nested amb-exp)
  (let ((flag #f))
  (ambc
    (lambda (succeed fail)
      (set! flag (not flag))
      (if flag
        (amb-exp succeed fail)
        (fail))))))

(define (amb-range-nested low high)
  (nested
   (lambda (succeed fail)
     (succeed (rand-float low high)))))

(define (amb-unit-circle-nested)
  (let ((x (amb-range -1 1))
        (y (amb-range-nested -1 1)))
    (require (<= (+ (square x) (square y)) 1))
    (list x y)))
\end{lstlisting}

Both of these methods correctly sample from the desired
distribution. (For instance, running the same chi-squared test on
\texttt{amb-unit-circle-nested} yielded a $p$-value of 0.9888,
indicating no reason to believe that the observed distribution was any
different from the expected distribution.)  However, both require
essentially implementing two versions of \texttt{amb-range}: the first
strategy duplicates \texttt{amb-range}'s definition of
\texttt{amb-ranges}, and the second strategy duplicates it in
\texttt{amb-range-nested}. One area we're still actively working on is
finding a way to ensure uniform randomness in a generic way that does
not require duplicating or re-writing any functionality.

Given a way to sample points randomly from a domain, implementing
Monte Carlo integration is simple. Given a function \texttt{func} that
takes $d$-tuples and a function \texttt{rand} to randomly sample
$d$-tuples from a domain, we can write Monte Carlo integration as
follows:
\begin{lstlisting}
(define (monte-carlo-integrate func rand num area)
  (define (sample sum n)
    (if (>= n num)
      (/ sum n)
      (sample (+ sum (func (rand))) (+ n 1))))
  (* area (sample 0 0)))
\end{lstlisting}
In this code, \texttt{num} is the number of points to sample, and
\texttt{area} is the area/volume of the domain, which we need because
the answer returned by Monte Carlo integration is the average value of
the function at the sampled points multiplied by this area/volume.

For example, we can run:
\begin{lstlisting}
(monte-carlo-integrate
  (lambda (point)
    (let ((x (car point))
          (y (cadr point)))
      (* (+ 1 x) (+ 2 y))))
  amb-unit-circle-ranges
  20
  (acos -1)) ; (acos -1) equals pi

;;; Amb-Eval input:
(monte-carlo-integrate
  (lambda (point)
    (let ((x (car point))
          (y (cadr point)))
      (* (+ 1 x) (+ 2 y))))
  amb-unit-circle-ranges
  30
  (acos -1))

;;; Starting a new problem
;;; Amb-Eval value:
6.334461308333196
\end{lstlisting}
The exact result of the integral is $2\pi \approx 6.28$.

\subsection{Probability objects}

We represented probability distributions (``probobjs'') as ambiguous
values, and implemented a number of functions to create and manipulate
them as random variables.
\begin{itemize}
\item \textbf{p:sum}: Returns a {probobj} that is the sum of the input
  {probobj}s.
\item \textbf{p:mult}: Returns a {probobj} that is the product of the
  input {probobj}s.
\item \textbf{p:scale}: Returns a {probobj} that is the scaled form of
  the input.
\item \textbf{p:shift}: Returns a {probobj} that is a shifted version
  of the input.
\end{itemize}

Once we had established a set of operations to perform on the
{probobj}s, we are then able to generate more complex probability
distributions from the initial uniform probability distribution. In
order to help ensure the probability distributions are correct, and to
visualize the output of the {probobj}s, we also implemented a
``p:display'' function that would generate a visual representation of
the {probobj} by taking many samples which are then placed into bins
across the distribution.

In addition to the methods that we created to manipulate {probobj}s,
we are also able to use our \texttt{ambc} construction to generate
{probobj}s deriving from the input one. For example, we can sample
from the part of the normal distribution above $x$ by using:

\begin{lstlisting}
(define (p:normal>x x)
  (lambda (succeed fail)
    (let ((p (ambc p:normal)))
      (require (> p x))
      (succeed p))))
\end{lstlisting}

Through the use of these objects, we are then easily able to implement
procedures on probability distributions using \texttt{ambc} to select across
them. While this form of {probobj} proves to be simple to use, while still
allowing complexity in the distributions that can be represented, there are
alternative methods to represent {probobj}s that have other useful
functionality. Some examples of alternative implementations include:

\begin{itemize}
  \item Probability Lists: Each probability object is represented by a list of
    values, generated to match the needed probability distribution.
  \item Parameterized Distributions: Each probability object is represented by a
    set of parameters to a generalized distribution that can generate the values
    for the distribution on constant time, rather than combining multiple
    probability distributions to generate the expected distribution.
\end{itemize} 

\section{Directions for future work}

Our main remaining issue is inefficient implementation of the
environment component.  We could attempt to implement environment
frames as some data structrure with copy-on-write semantics, but for
computationally intensive studies of probability it would be better to
abandon the embedded interpreter and implement \texttt{ambc} as a
macro in the base Scheme interpreter.  Of course, this would bring its
own set of implementation challenges.

Given that some branches are replayed many times, it might also be
worthwhile to investicate mechanisms by which code execution could be
memoized.

\section{Running our code}

Our code is available to view or download at
\url{http://github.com/dvorak42/pramb}. To load our code, first run
\texttt{(cd "src")} and then \texttt{(load "load")}. To start our
custom interpreter, simply run \texttt{(init)}. This interpreter will
have support for \texttt{ambc} but not for any constructs built on top
of it, such as \texttt{amb} or \texttt{require}. These are defined by
\texttt{embedded-amb.scm}, which you can load into the interpreter by
running \texttt{(init "embedded-amb.scm")} instead of the init command
above.

Likewise, many of the probability functions are defined in
\texttt{embedded-prob.scm}. You can instruct init to load multiple
files into the interpreted environment, such as \texttt{(init
  "embedded-amb.scm" "embedded-prob.scm")}. Finally, if the
interpreter quits due to an error, you can either re-\texttt{init} to
return to an interpreter with a default environment, or run
\texttt{(driver-loop)} to resume the interpreter in its former
environment.

\end{document}
